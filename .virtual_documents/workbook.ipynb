import numpy as np
import tensorflow as tf
from tensorflow import keras
import time
import pickle
from collections import deque
from pingpong import pingpongRL


alpha=0.01
alpha_decay=0.01
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(24, input_dim=5, activation='tanh')) # input the 5 dimensions of the state
model.add(tf.keras.layers.Dense(48, activation='tanh'))
model.add(tf.keras.layers.Dense(2, activation='linear')) # output the Q-values (value function) for the two actions

optimizer=keras.optimizers.Adam(learning_rate=alpha, decay=alpha_decay)
loss = keras.losses.MeanSquaredError()
model.compile(optimizer=optimizer, loss=loss)


state = np.array([[1,1,1,1,0]])


start = time.time()
np.argmax(model.predict(state))
print(time.time()-start)


PATH = "C:/Users/tomas/Desktop/summer projects/game/RL/agents/"
mem = pickle.load(open(f"{PATH}{210623}_{1609}.p", "rb"))


episode = [mem[0]]


episode = []
for m in mem:
    episode.append(m[0][0])
    if m[4]:
        break


game = pingpongRL.Game()


game.playback(episode)



